{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown Syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Markdown 문법](https://velog.io/@wonhs717/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4Markdown-%EB%AC%B8%EB%B2%95-ytk5zemk0x)\n",
    "- [Markdown 사용법 총정리](https://heropy.blog/2017/09/30/markdown/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allocation of GPU<br>\n",
    "\n",
    "## 하나의 GPU 할당 방법\n",
    "\n",
    "```python\n",
    "    with tf.device('/gpu:1'):\n",
    "         ### model = ... (model를 만들어서 compile하고 fit 해주면 됨) \n",
    "```\n",
    "---\n",
    "\n",
    "## 여러개의 GPU 할당 방법 ([참고])(https://ahnjg.tistory.com/34)\n",
    "```python \n",
    "    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:2\", \"/gpu:3\"])\n",
    "    with strategy.scope():\n",
    "        ### model = ... (model를 만들어서 compile하고 fit 해주면 됨) \n",
    "```\n",
    "---\n",
    "\n",
    "## GPU memory 확인법 \n",
    "- jupyter notebook에서 command line 실행 or **terminal**로 실행(추천)\n",
    "```python\n",
    "    !nvidia-smi\n",
    "```\n",
    "  - 실시간 모니터링법: \n",
    "  > $ watch -n 0.1 nvidia-smi\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi-GPU 사용 setting  ([참고](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth))\n",
    "\n",
    "- 그냥 MirroredStrategy 써서 바로 scope() 안에서 모델을 돌리면 tf는 GPU의 거의 모든 memory를 mapping\n",
    "  - 한번에 전체를 지니고 안에서 필요한 부분을 할당해서 쓰는 느낌 -> memory fregmentation을 최소화 할 수 있음\n",
    "  - 그러나 tf의 특성상 gpu:2, gpu:3을 써도 gpu:0을 거치는 것 같아서 gpu:0을 전부 쓰고 있으면 나머지 gpu를 따로 사용할 때 접근에서 문제가 생기는 것 같음 (Error 문구: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize)\n",
    "  - 그래서 아래와 같이 tf가 gpu에서 처음 지정한 메모리만큼 사용하게 하거나 필요한만큼만 계속 늘려서 갖다 쓰게 하니 해결됨\n",
    "\n",
    "\n",
    "- 주의사항: 아래 방법을 쓸 때, gpu 돌리기 전에 먼저 해야함. 즉 gpu 세팅해서 모델을 돌리기 전에 설정을 해야 함(아니면 initialized 후에 modify할 수 없다고 뜸 -> 그럴땐 kernel를 restart에서 다시 실행). 설정은 각 쥬피터 노트북마다 매번할때 각각 해줘야 함\n",
    "\n",
    "<br>\n",
    "\n",
    "### tf가 특정 gpu만 접근하도록 하기\n",
    "\n",
    "```python\n",
    "import tensorflow as tf \n",
    " \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 텐서플로가 1, 2번째 GPU만 사용하도록 제한\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0:2], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 접근 가능한 장치가 설정되어야만 합니다\n",
    "        print(e)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "### tf가 접근하는 gpu의 memory 용량 제한 (ex. 4GB)\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*4)])\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*4)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "```\n",
    "  - 단점: 모델의 구조가 커서 텐서에 저장해야 될 메모리가 많을 경우, allocation 에러 뜸\n",
    "\n",
    "<br>\n",
    "\n",
    "### tf가 필요한 만큼만 계속 갖다 쓰게 하기 (추천)\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU 메모리 비우는 방법\n",
    "\n",
    "- GPU를 돌린 해당 커널을 종료\n",
    "\n",
    "\n",
    "- container exit 했다가 다시 start, attach (가장 확실)\n",
    "\n",
    "\n",
    "- tf에서 session 연 후에는 항상 닫아주기\n",
    "  - keras.model.fit을 하면 session이 열리므로 train이 끝난 후에 session을 닫아줘야 함\n",
    "```python\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- 특정 GPU 메모리 relase (확실!) \n",
    "  - Tensorflow is just allocating memory to the GPU, while CUDA is responsible for managing the GPU memory.\n",
    "If CUDA somehow refuses to release the GPU memory after you have cleared all the graph with K.clear_session(), then you can use the cuda library to have a direct control on CUDA to clear up GPU memory. ([링크](https://stackoverflow.com/questions/51005147/keras-release-memory-after-finish-training-process/52354943))\n",
    "\n",
    "```python\n",
    "from numba import cuda\n",
    "cuda.select_device(2) # GPU 2번을 끌때\n",
    "cuda.close()\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- numba 모듈 이용 : 비우는 것 같은데 확실히 잘 작동하는지는 모르겠음\n",
    "\n",
    "```python\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "```\n",
    "\n",
    "\n",
    "- sudo nvidia-smi --gpu-reset –i gpuID : 강제로 gpu memory 지우기\n",
    "(or sudo nvidia-smi –r) <br>\n",
    "cf) ‘GPU Reset couldn't run because GPU0 is the primary GPU’ 라는 에러 문구 뜨면 sudo rmmod nvidia_uvm으로 해결가능하나 물리적인 재부팅이 제일 확실하고 좋은 방법\n",
    "\n",
    "\n",
    "- 최후의 수단: linux restart(재부팅)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경 세팅\n",
    "\n",
    "\n",
    "## Docker\n",
    "- [Tensorflow와 호환되는 CUDA, cuDNN 설치하는 법](https://coding-groot.tistory.com/87)\n",
    "  - 또는 리눅스에서 docker(또는 window)를 사용하는 경우, [docker hub](https://hub.docker.com/r/nvidia/cuda/)에서 필요한 버전이 담긴 nvidia/cuda image을 다운받아 container를 만들면 됨\n",
    "\n",
    "\n",
    "- 자세한 내용은 구글독 문서 (docker 사용법.docs) 참조\n",
    "\n",
    "- [Anaconda 가상환경 설치](https://kyumdoctor.tistory.com/26)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSH tunneling\n",
    "- [SSH tunneling - the black magic for data science](https://medium.com/hackernoon/the-ssh-black-magic-for-data-science-acd6f65e8528) <br>\n",
    "\n",
    "(tunnelssh) <br>\n",
    "ssh -o ExitOnForwardFailure=yes -N -R *:8000:localhost:8888 -i pivr.pem -o StrictHostKeyChecking=no pivr@54.180.210.78 \n",
    "<br>\n",
    "\n",
    "(.ssh) <br>\n",
    "known_hosts\n",
    "<br>\n",
    "tunnel-pivr.pem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyterlab\n",
    "\n",
    "* [참고 블로그](https://onesixx.com/jupyter-lab/)\n",
    "\n",
    "### execute time 사용하기\n",
    "1. terminal에서 conda actiavte (가상환경)\n",
    "2. 해당 가상환경으로 들어갔으면, conda install -c conda-forge jupyterlab_execute_time 후 y\n",
    "3. 설치 후, settings -> advanced settings editor 에서 user preferences 에다가 아래 입력 후 저장\n",
    "{\n",
    "    \"recordTiming\": true\n",
    "}\n",
    "\n",
    "\n",
    "### CPU & Memory 모니터링\n",
    "* [참고 블로그](https://ebbnflow.tistory.com/329)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras 모델 저장 및 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **모델의 아키텍처 및 구조 저장:**   model.to_json()으로 모델의 구조 정보를 가져오고'model.json' 형태로 저장 후 model_from_json으로 불러오기\n",
    "- **모델의 weights 저장:** 'weights.hdf5' 형태로 저장하고 model.load_weights(weight_path)로 불러오기 <br><br>\n",
    "- **모델의 모든 정보 저장:** [Keras 모델 저장 및 로드](https://www.tensorflow.org/guide/keras/save_and_serialize?hl=ko) <br>\n",
    " -- model.save()로 저장하면 폴더를 생성함 - 모델 아키텍처 및 훈련 구성(옵티마이저, 손실 및 메트릭 포함)은 saved_model.pb에 저장됩니다. 가중치는 variables/ 디렉토리에 저장 <br>\n",
    " -- tf.keras.models.save_model()로 'model.h5' 형태로 저장 후 tf.keras.models.load_model()로  불러옴. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras validation split\n",
    "\n",
    "- keras.model의 fit함수에서 shuffle=True는 매 epoch마다 training set를 shuffle하는 것이고, validation_split=0.1을 하면 처음 주어진 training set에서 뒤에 10%를 순서대로 뽑아 validation set으로 처리한다. 따라서 fit하기 전에 따로 training set를 random하게 shuffle해야 한다.\n",
    "\n",
    "- train의 x값과 y값의 shuffle은 아래와 같이 하면 된다.\n",
    "\n",
    "```python\n",
    "    ids = np.arange(x_train.shape[0])\n",
    "    np.random.shuffle(ids)\n",
    "\n",
    "    x_train = x_train[ids]\n",
    "    y_train = y_train[ids]\n",
    "    y_train_bin = y_train_bin[ids]\n",
    "```\n",
    "\n",
    "- 그러나, **각 환자마다 data augmentation이 많이 되었으면** test set 나누듯이 validation도 train set 내에서 환자 caseid 단위로 나눠야함 **(중요!!!!!)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model class API\n",
    "- [Model](https://keras.io/ko/models/model/)\n",
    "- [Optimizer](https://keras.io/ko/optimizers/)\n",
    "- [Losses](https://keras.io/ko/losses/)\n",
    "- [Regression metrics](https://keras.io/api/metrics/regression_metrics/) : y_pred와 y_test 사이의 mse나 compile API()에서의 사용법까지 잘 나와 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras.model 그리기\n",
    "\n",
    "- [Model plotting utilities](https://keras.io/api/utils/model_plotting_utils/)\n",
    "\n",
    "```python\n",
    "    tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "- ..\n",
    " - required: pydot, anaconda, graphviz를 설치하고 안될 경우 path 설정까지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원하는 layer의 output 구하기\n",
    "- [Keras, How to get the output of each layer?](https://stackoverflow.com/questions/41711190/keras-how-to-get-the-output-of-each-layer)\n",
    "\n",
    "```python\n",
    "from keras import backend as K\n",
    "\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functors = [K.function([inp], [out]) for out in outputs]    # evaluation functions\n",
    "\n",
    "# Testing\n",
    "test = np.random.random(input_shape)[np.newaxis,...]\n",
    "layer_outs = [func([test]) for func in functors]\n",
    "```\n",
    "\n",
    "\n",
    "## keras.backend\n",
    "\n",
    "```python\n",
    "from keras import backend as K\n",
    "\n",
    "K.int_shape(inp) # return shape of input or output\n",
    "K.function([inp], [model.layers[1].output, model.layers[-1].output]) # 이처럼 초기 input을 넣어주면 원하는 layer의 output 계산\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [tensorflow/models](https://github.com/tensorflow/models/tree/master/research)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  global max pooling layer:  [StackExchange Link]('https://stats.stackexchange.com/questions/257321/what-is-global-max-pooling-layer-and-what-is-its-advantage-over-maxpooling-layer')\n",
    "<Blockquote> \n",
    "As described in this paper that proposed global average pooling (GAP): <br><br>\n",
    "Conventional convolutional neural networks perform convolution in the lower layers of the network. For classification, the feature maps of the last convolutional layer are vectorized and fed into fully connected layers followed by a softmax logistic regression layer. This structure bridges the convolutional structure with traditional neural network classifiers. It treats the convolutional layers as feature extractors, and the resulting feature is classified in a traditional way. <br><br>\n",
    "However, the fully connected layers are prone to overfitting, thus hampering the generalization ability of the overall network. Dropout is proposed by Hinton et al as a regularizer which randomly sets half of the activations to the fully connected layers to zero during training. It has improved the generalization ability and largely prevents overfitting. <br><br>\n",
    "In this paper, we propose another strategy called global average pooling to replace the traditional fully connected layers in CNN. The idea is to generate one feature map for each corresponding category of the classification task in the last mlpconv layer. Instead of adding fully connected layers on top of the feature maps, we take the average of each feature map, and the resulting vector is fed directly into the softmax layer. One advantage of global average pooling over the fully connected layers is that it is more native to the convolution structure by enforcing correspondences between feature maps and categories. Thus the feature maps can be easily interpreted as categories confidence maps. Another advantage is that there is no parameter to optimize in the global average pooling thus overfitting is avoided at this layer. Futhermore, global average pooling sums out the spatial information, thus it is more robust to spatial translations of the input. We can see global average pooling as a structural regularizer that explicitly enforces feature maps to be confidence maps of concepts (categories). This is made possible by the mlpconv layers, as they makes better approximation to the confidence maps than GLMs.\n",
    "</Blockquote>\n",
    "\n",
    "\n",
    "- [Max poolling, average pooling](https://www.machinecurve.com/index.php/2020/01/30/what-are-max-pooling-average-pooling-global-max-pooling-and-global-average-pooling/#how-max-pooling-benefits-translation-invariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception\n",
    "- [Inception(GoogLeNet)](https://kangbk0120.github.io/articles/2018-01/inception-googlenet-review)\n",
    "\n",
    "- [CNN의 발자취](https://m.blog.naver.com/PostView.nhn?blogId=kmkim1222&logNo=221524681282&proxyReferer=https:%2F%2Fwww.google.com%2F)\n",
    "  - Inception v1: 1x1 conv layer이 소개되며 네트워크 성능을 크게 저하시키지 않으면서 매개변수의 수를 감소시킬 수 있음\n",
    "  - Inception v2: prelayer + inception layer(network in network) + global average pooling + auxillary classifier + convolution factorization + batch normalization\n",
    "  - Inception v3: googlenet이라고 불리며 더 발전시킴\n",
    "  - Inception ResnetV2: Inception model과 Resnet model의 장점을 합침. 메모리와 연산 비용이 v3보다 2배 더 들지만\n",
    "  \n",
    "- [Short history of the inception](https://nicolovaligi.com/history-inception-deep-learning-architecture.html): inception v3 논문\n",
    "\n",
    "- [Inception modules: explained and implementated](https://hacktildawn.com/2016/09/25/inception-modules-explained-and-implemented/): 아주 잘 정리되어 있는 글\n",
    "\n",
    "- [Inception V3: Transfer Learning](https://jsideas.net/Inception_v3_transfer_learning/)\n",
    "\n",
    "- [구글 인셉션(GoogleNet) 알아보기](https://ikkison.tistory.com/86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## non-local neural network\n",
    "- [논문정리](https://velog.io/@haejoo/Non-Local-Neural-Networks-%EB%85%BC%EB%AC%B8-%EC%A0%95%EB%A6%AC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Fast R-CNN](https://ganghee-lee.tistory.com/36?category=863370)\n",
    "- [RCNN 부터 Mask R-CNN까지 (1) R-CNN ~ Fast R-CNN](https://woosikyang.github.io/fast-rcnn.html)\n",
    "  - [Region Proposal Network (RPN) — Backbone of Faster R-CNN](https://medium.com/egen/region-proposal-network-rpn-backbone-of-faster-r-cnn-4a744a38d7f9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSTM cell in keras.layers.LSTM\n",
    "  - return_state = True를 하면\n",
    "    - [Return sequences and return states](https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습이 안되는 경우, 여러가지 원인이 있음. 주로 gradient vanishing이나 exploding과 관련\n",
    "1. Activation Function: 예를 들어 CNN에서 ReLU를 쓰면 음수인 값은 0이기에 처음에 강한 negative weight이 걸리면 계속 0이 되어 학습x\n",
    "  - 참고: [Using Leaky ReLU](https://www.machinecurve.com/index.php/2019/11/12/using-leaky-relu-with-keras/)\n",
    "2. Input의 normalization: normalize 되지 않아 큰 값이 들어오면 학습 초기 구간에서 특정 gradient에 과부하가 걸릴 수도\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "- overfitting을 막기 위한 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 loss (Weight Decay)\n",
    "- [Regularization - 라온피플](https://m.blog.naver.com/laonple/220527647084)\n",
    "- [How to Use Weight Decay to Reduce Overfitting of Neural Network in Keras](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/) : 코드도 잘 정리되어 있고 많은 논문들의 예시도 담고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalizaion\n",
    "- [Batch Normalization 설명 및 구현](https://shuuki4.wordpress.com/2016/01/13/batch-normalization-%EC%84%A4%EB%AA%85-%EB%B0%8F-%EA%B5%AC%ED%98%84/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원래는 Aadm을 많이 썼는데 regularization을 잘 시키는 새로운 optimizer들이 나옴\n",
    "\n",
    "### AdamW ([참고](https://hiddenbeginner.github.io/deeplearning/paperreview/2019/12/29/paper_review_AdamW.html))\n",
    "  - 코드\n",
    "  ```python\n",
    "    import tensorflow_addons as tfa\n",
    "    tfa.optimizers.AdamW(learning_rate=0.001, scedule)\n",
    "```\n",
    "  - [참고2](https://github.com/OverLordGoldDragon/keras-adamw) : 추천 - !pip install keras-adamw 해서 사용하면 됨\n",
    "\n",
    "\n",
    "- learning rate schedular를 keras.model.fit의 callbacks=[callbacks]로 대입 ([참고1](https://stackoverflow.com/questions/60029027/decay-parameter-of-adam-optimizer-in-keras), [참고2](https://dodonam.tistory.com/178))\n",
    "\n",
    "```python\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "def decay_schedule(epoch, lr):\n",
    "    # decay by 0.1 every 5 epochs; use `% 1` to decay after each epoch\n",
    "    if (epoch % 5 == 0) and (epoch != 0):\n",
    "        lr = lr * 0.1\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(decay_schedule)\n",
    "model.fit(x, y, epochs=50, callbacks=[lr_scheduler])\n",
    "\n",
    "```\n",
    "\n",
    "### RAdam\n",
    "- [radam 정리](https://zzaebok.github.io/deep_learning/RAdam/) : Adam의 한계점과 RAdam에 대해서\n",
    "- [LiyuanLucasLiu/RAdam](https://github.com/LiyuanLucasLiu/RAdam) : RAdam 논문 저자의 githhub\n",
    "- [keras 버전의 RAdam](https://github.com/CyberZHG/keras-radam)\n",
    "```python\n",
    "!pip install keras-rectified-adam\n",
    "\n",
    "* 사용법\n",
    "from keras_radam import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T05:56:04.823264Z",
     "start_time": "2021-01-03T05:56:00.059521Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-rectified-adam\n",
      "  Downloading keras-rectified-adam-0.17.0.tar.gz (11 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-rectified-adam) (1.17.3)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-rectified-adam) (2.4.3)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras-rectified-adam) (1.15.0)\n",
      "Building wheels for collected packages: keras-rectified-adam\n",
      "  Building wheel for keras-rectified-adam (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-rectified-adam: filename=keras_rectified_adam-0.17.0-py3-none-any.whl size=14783 sha256=5b697f51e6263e99dc7730f6af49cc23398530b991f88a5b1805b693a71ef9a1\n",
      "  Stored in directory: /root/.cache/pip/wheels/1d/49/44/913b6f7b45fa25ce170bdefe45f7d6c57eb44a20f746570659\n",
      "Successfully built keras-rectified-adam\n",
      "Installing collected packages: keras-rectified-adam\n",
      "Successfully installed keras-rectified-adam-0.17.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-rectified-adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유용한 Library\n",
    "\n",
    "## Neurokit\n",
    "* 주소 : [git](https://github.com/neuropsychology/NeuroKit)\n",
    "* [Extract and Visualize Individual Heartbeats](https://neuropsychology.github.io/NeuroKit/examples/ecg_heartbeats/ecg_heartbeats.html)\n",
    "```python\n",
    "    import neurokit2 as nk\n",
    "    \n",
    "    # Simulate 30 seconds of ECG Signal (recorded at 250 samples / second)\n",
    "    #ecg_signal = nk.ecg_simulate(duration=30, sampling_rate=250)\n",
    "    # 또는 raw ECG signal(one dimensional array or list)가 있으면 사용\n",
    "    \n",
    "    # Automatically process the (raw) ECG signal\n",
    "    signals, info = nk.ecg_process(ecg_signal, sampling_rate=250)\n",
    "\n",
    "    # Extract clean ECG and R-peaks location\n",
    "    rpeaks = info[\"ECG_R_Peaks\"]\n",
    "    cleaned_ecg = signals[\"ECG_Clean\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기존에 다른 모델에서 학습해둔 결과를 이용 -> 이 transfer learning 덕분에 cnn해서 input이 천개여도 충분히 좋은 모델이 나옴\n",
    "- 그래서 이미지 관련 cnn은 훈련하기 편함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attension mechanism\n",
    "- [어텐션 메커니즘](https://wikidocs.net/22893)\n",
    "- [Attention in Neural Networks - 1. Introduction to attention mechanism](https://buomsoo-kim.github.io/attention/2020/01/01/Attention-mechanism-1.md/)\n",
    "\n",
    "\n",
    "## CNN의 적용\n",
    "- [BAM and CBAM](https://blog.lunit.io/2018/08/30/bam-and-cbam-self-attention-modules-for-cnn/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K-fold cross validation은 hyperparameter를 찾기 위한 방법\n",
    "- training set을 k-fold로 나눠서 형성된 k개의 (Training, Test) set를 각각 학습시켜서 accuracy를 계산\n",
    "- 이렇게 결정된 hyperparameter들로 최종 모델을 만들고 다시 학습(이땐 그냥 validation을 split해서 나눠도 무방)\n",
    "- 최종 성능 평가는 처음에 따로 빼둔 test set에 대해 계산\n",
    "- 애초에 validation set이란 최적의 모델을 찾기 위해 만든 set이기 때문!!!\n",
    "- 원래는 hyperparamter 찾을 때 k-fold 해야 하지만 이론적으로 시간이 너무 많이 소요되기에 일단 search할땐 그냥 split해서 사용하다가 잘 나온 모델들간의 선택을 할때 k-fold로 성능을 비교해서 논문에 제시해주면 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization(Tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대표적으로 grid search와 random search가 있음. grid search는 모든 hyperparameter 조합에 대해서 알아보는 것으로 golden standard이긴 하지만 시간이 오래 걸림. 그래서 보통 random search를 많이 함.\n",
    "- 참고: [Random Search vs Grid Search](https://shwksl101.github.io/ml/dl/2019/01/30/Hyper_parameter_optimization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- python은 sklearn에서 GridSearchCV와 RandomizedSearchCV를 제공\n",
    "```python\n",
    "    from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "```\n",
    " - 공식 사이트: [sklearn.model_selection.RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    " \n",
    "- grid search나 random search를 keras model에 적용한 예시 \n",
    "  - KerasClassifier 이용; [Grid 예시1](https://www.kaggle.com/arrogantlymodest/randomised-cv-search-over-keras-neural-network),   **[Random 예시1](http://ethen8181.github.io/machine-learning/keras/nn_keras_hyperparameter_tuning.html)**\n",
    "    - keras로 딥러닝 모델을 짠 경우, KerasClassifier에 keras 모델을 함수 형태로 집어넣고 scikit-learn의 RandomizedSearchCV나 GridSearchCV를 이용\n",
    "    - [KerasClassifier 사용 예시](https://buomsoo-kim.github.io/keras/2019/07/12/Easy-deep-learning-with-Keras-19.md/)\n",
    "    - 참고로 regression은 KerasRegressor(build_fn=None, **sk_params)가 있음\n",
    "    > The build_fn should construct, compile and return a Keras model, which will then be used to fit/predict. One of the following three values could be passed to build_fn:\n",
    "    > 1. A function\n",
    "    > 2. An instance of a class that implements the __call__ method\n",
    "    > 3. None. This means you implement a class that inherits from either\n",
    "KerasClassifier or KerasRegressor. The __call__ method of the present class will then be treated as the default build_fn.\n",
    "...\n",
    "sk_params takes both model parameters and fitting parameters. Legal model parameters are the arguments of build_fn. Note that like all other estimators in scikit-learn, build_fn should provide default values for its arguments, so that you could create the estimator without passing any values to sk_params.\n",
    "  - Visualization\n",
    "    - [[ Python ] Scikit-Learn Pipeline + RandomizedSearchCV + shap,eli5](https://data-newbie.tistory.com/366)\n",
    "    \n",
    "    \n",
    "    \n",
    "<br><br>\n",
    "- multi-core를 사용하는 방법(training, evaluation, hyperparamter tuning) ([참고](https://machinelearningmastery.com/multi-core-machine-learning-in-python/))\n",
    "  - os.cpu_count()로 사용가능한 cpu 개수 알 수 있음 (python 3.4 이상. 3.4이하에선 multiprocessing.cpu_count())\n",
    "  - scikit learn의 n_jobs 인자에서 이를 결정\n",
    "    - n_jobs=-1은 가능한 모든 CPU 사용\n",
    "    - hyperparamter tuning할 때 searching에 multi-core 몰빵하는게 효율적\n",
    "  - [tune-sklearn](https://towardsdatascience.com/5x-faster-scikit-learn-parameter-tuning-in-5-lines-of-code-be6bdd21833c)\n",
    "  <br>\n",
    "- 다른 방법으로 Bayesian Optimization(BO)나 Particle Swarm Optimization(PSO)이 있음\n",
    "  - [Bayesian Optimization](https://blog.naver.com/PostView.nhn?blogId=dpfkdlt&logNo=221678800067&from=search&redirect=Log&widgetTypeCall=true&directAccess=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation - Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUPRC [링크1](https://m.blog.naver.com/sw4r/221681933731)\n",
    "  - precision : positive predictive value로 TP / (TP + FP). 즉 내가 답이라고 예측한 값 중 얼마나 잘 맞추었는지\n",
    "  - recall : sensitivity, true positive rate. TP / (TP + FN). 즉 실제 positive 중 얼마나 잘 예측하는지\n",
    "  - F1 score : 2 x (precision x recall) / (precision + recall). 즉, preicison과 recall의 조화 평균\n",
    "  - Precision-Recall curve (x축이 recall, y축이 precision)\n",
    " <br> \n",
    "\n",
    "\n",
    "## AUROC [링크1](https://riptutorial.com/ko/machine-learning/example/14446/auroc--receiver-operating-characteristic--%EA%B3%A1%EC%84%A0-%EC%95%84%EB%9E%98-%EC%98%81%EC%97%AD)\n",
    "  - sensitivity : recall과 같음. TPR (true positive rate)\n",
    "  - specificty : true negative rate. TN / (TN + FP)\n",
    "  - roc 그릴때 y_pred순으로 나열해서 1에 가까운값부터 true면 위로, false면 우측으로 이동(즉, true->false 발생시 꺾이는점 생김)하면서 그린다\n",
    "  - 만약에 roc가 한 점에서 꺾인다? => y_pred를 0 또는 1 값으로 한것으로 결과가 좋아질 수 밖에 없음. 이런 논문은 거르기\n",
    "\n",
    "\n",
    "## AUROC, AUPRC 코드 (계산 및 plotting)\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# y_test_bin은 0 또는 1, y_pred는 연속적인 값 (roc 그릴때 꼭 한쪽은 0 또는 1, 다른쪽은 연속이고 굳이 0~1 사이일 필요는 x)\n",
    "# Model AUROC, AUPRC\n",
    "false_positive_rate1, true_positive_rate1, threshold = roc_curve(y_test_bin, y_pred)\n",
    "precision1, recall1, _ = precision_recall_curve(y_test_bin, y_pred)\n",
    "\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "prc_auc = auc(recall, precision)\n",
    "print('test set auroc: {:.6f},  test set auprc: {:.6f}'.format(roc_auc, prc_auc))\n",
    "\n",
    "\n",
    "# plotting auprc\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "\n",
    "# ax1: auroc\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.set_title('Receiver Operating Characteristic')\n",
    "ax1.set_xlabel(\"False Positive Rate(1 - Specificity)\")\n",
    "ax1.set_ylabel('True Positive Rate(Sensitivity)')\n",
    "\n",
    "ax1.plot(false_positive_rate, true_positive_rate, 'b', label='Model 1 (AUC = %0.4f)'% roc_auc)\n",
    "ax1.plot([0,1],[1,1],'y--')\n",
    "ax1.plot([0,1],[0,1],'r--')\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "# ax2: auprc\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.set_title('Precision - recall curve')\n",
    "ax2.set_xlabel(\"Precision\")\n",
    "ax2.set_ylabel('Recall')\n",
    "ax2.plot(recall, precision, 'b', label='Model 1 (AUC = %0.4f)'% prc_auc)\n",
    "ax2.legend(loc='lower right')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "  \n",
    "<br>\n",
    "\n",
    "## Confusion matrix\n",
    "<center><img src=\"Images/confusionMatrix.jpg\" width=\"80%\" height=\"80%\"></center> \n",
    "\n",
    "### sklearn.metrics\n",
    "- 그러나 sklearn.metrics의 plot_confusion_matrix는 classifier를 이용하는 경우\n",
    "\n",
    "```python\n",
    "### calculating confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_true, y_pred, sample_weight)\n",
    "# y_pred는 연속적인 값이 아닌 threshold에 대해 계산. 이때 threshold는 accuracy를 최대로 하냐, sensitivity를 최대로 하냐 등 목적에 따라 다름 (ex 선별검사는 sensitivity를 최대로 하는 threshold 이용). 즉 이진분류의 경우 y_pred>thval로 넣어줘야 함\n",
    "```\n",
    "\n",
    "### scikitplot.metrics\n",
    "- y_pred와 y_true만 라벨링 잘 되어있으면 multiclass에 대해서도 confusion matrix를 그려줌. 그러나 sample weight은 적용 못함\n",
    "\n",
    "```python\n",
    "### plotting confusion matrix - . 일반적으로는 아래 함수\n",
    "from scikitplot.metrics import plot_confusion_matrix\n",
    "\n",
    "# 공식문서: https://scikit-plot.readthedocs.io/en/stable/metrics.html\n",
    "plot_confusion_matrix(y_true, y_pred, labels=None hide_zeros=True, title='Confusion Matrix')\n",
    "```\n",
    "\n",
    "### customized plot_confusion_matrix\n",
    "\n",
    "```python\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def cplot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, '{:.0f}'.format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## Others\n",
    "\n",
    "- specificity : true negative rate. TN / (FP+TN)\n",
    "  - [참고](https://www.healthnewsreview.org/toolkit/tips-for-understanding-studies/understanding-medical-tests-sensitivity-specificity-and-positive-predictive-value/)\n",
    "    - sensitive: 실제 임신한 사람 중 임신했는지를 얼마나 잘 맞추는가\n",
    "    - specific: 임신 안 한 사람 중 임신안했는지를 얼마나 잘 맞추는가\n",
    "<br>\n",
    "\n",
    "- accuracy = correct prediction / total prediction = (TP + TN) / (TP+ FP + TN + FN)\n",
    "\n",
    "\n",
    "### 참고문헌\n",
    "- [Evaluation Metrics](http://www.davidsbatista.net/blog/2018/08/19/NLP_Metrics/) : 각각의 개념과 unbalanced data에서 PRC가 ROC보다 좋다는 내용\n",
    "- [ROC curve](https://angeloyeo.github.io/2020/08/05/ROC.html) : threshold에 관한 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics (모델 성능 평가)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "## Loss\n",
    "- mse, rmse, mae\n",
    "\n",
    "- R2 square\n",
    "\n",
    "## Metrics\n",
    "- auroc: training 과정에서 계산되는 auroc는 0 또는 1로 이루어진 y_train_bin에 대해 계산되는 것이 아닌 0~1 사이 y_train에 대해 계산되므로 classification에서 사용하는 auroc와는 차이가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class weight, sample weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [How to set sample_weight in Keras?](https://androidkt.com/set-sample-weight-in-keras/)\n",
    "\n",
    "- data가 unbalance한 경우, 각 구간(class)마다 동일한 정도로 학습을 시키고 싶으면 sample weight을 (총합)/class의 bins로 준다\n",
    "\n",
    "- keras.model을 fit할 때, train set와 val set에 sample weight을 줄 수 있음\n",
    "  - keras.model.fit(x_train, y_train, sample_weight = train_sample_weight, validation_data = (x_val, y_val, val_sample_weight)...)\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T15:21:28.953151Z",
     "start_time": "2020-11-22T15:21:28.944396Z"
    }
   },
   "source": [
    "[Deep Learning With Weighted Cross Entropy Loss On Imbalanced Tabular Data Using FastAI](https://towardsdatascience.com/deep-learning-with-weighted-cross-entropy-loss-on-imbalanced-tabular-data-using-fastai-fe1c009e184c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbalanced data 다루는 법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sample weight나 class weight을 줄 수 있음\n",
    "\n",
    "\n",
    "- resampling을 함 -> 데이터수가 많으면 over-represented class에서 제거, 데이터수가 적으면 under-represented class에 sample을 추가\n",
    "  - **[SMOTE (Synthetic Minority Over-sampling Technique)]**(https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a) : from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning with noisy labels\n",
    "- Davood Karimi, Haoran Dou, Simon K. Warfield, Ali Gholipour,\n",
    "Deep learning with noisy labels: Exploring techniques and remedies in medical image analysis, Medical Image Analysis, Volume 65, 2020, 101759 [(논문)](https://www.sciencedirect.com/science/article/pii/S1361841520301237#bib0073)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "\n",
    "## Semi-supervised learning\n",
    "\n",
    "- [Semi-Supervised Learning 정리](https://medium.com/@kabbi159/semi-supervised-learning-%EC%A0%95%EB%A6%AC-a7ed58a8f023) : 여러가지 semi-supervised learning의 종류 소개 및 최신 링크\n",
    "\n",
    "\n",
    "## Unsupervised learning\n",
    "\n",
    "- [How to do Unsupervised Clustering with Keras](https://www.dlology.com/blog/how-to-do-unsupervised-clustering-with-keras/)\n",
    "  - **autoencoder**: 예를 들어 encoder로 10D 짜리 feature를 만들고 이를 다시 decoder에 넣어 원래 input을 만드는 모델\n",
    "  - 그 다음 이 10D 짜리 features를 K-means으로 10개의 cluster를 만듬\n",
    "  - [관련 github](https://github.com/Tony607/Keras_Deep_Clustering)\n",
    "  \n",
    "## Autoencoder\n",
    "- [variational autoencoder](https://keraskorea.github.io/posts/2018-10-23-keras_autoencoder/)\n",
    "- [Convolutional Autoencoder with Keras](https://www.kaggle.com/anmour/convolutional-autoencoder-with-keras)\n",
    "- [Convolutional Autoencoders for Image Noise Reduction](https://towardsdatascience.com/convolutional-autoencoders-for-image-noise-reduction-32fce9fc1763)\n",
    "\n",
    "### Deconvolution\n",
    "- [참고](https://analysisbugs.tistory.com/104)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 관련 파일 문법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 이동, 복사\n",
    "\n",
    "```python\n",
    "    # 필요한 모듈\n",
    "    import shutil, os\n",
    "\n",
    "    # 폴더의 하위 파일 이름 가져오기\n",
    "    cache_path = 'cache/PPG'\n",
    "    file_list = os.listdir(cache_path)\n",
    "\n",
    "    # 파일 위치 바꾸기\n",
    "    for file_name in file_list:\n",
    "        if 'PACU1_12' in file_name:\n",
    "            print(file_name)\n",
    "            shutil.move('cache/PPG2/'+file_name, 'cache/PPG/'+file_name)\n",
    "\n",
    "    # 파일 이름 바꾸기\n",
    "    for file_name in file_list:\n",
    "        if 'hbi_ppga2_' in file_name:\n",
    "            mod_name = 'hbi_ppga_' +file_name[10:]\n",
    "            print(file_name, '...changed')\n",
    "            os.rename(os.path.join(cache_path,file_name), os.path.join(cache_path,mod_name))\n",
    "            \n",
    "    # 파일 복사해서 옮기기 \n",
    "    shutil.copy(옮기고싶은 파일, 옮기려는 곳) # 옮기려는 곳이 디렉토리면 그 하위로, 파일이면 옮기고 싶은 파일로 대체\n",
    "    shutil.cpy2( `` ) # 파일의 모든 메타 정보까지 옮김 \n",
    "    \n",
    "    # 하위 모든 디렉토리 접근\n",
    "    os.walk 이용\n",
    "```\n",
    "\n",
    "  - [파일 복사 관련 링크](https://blog.naver.com/PostView.nhn?blogId=hankrah&logNo=221832296707&categoryNo=51&parentCategoryNo=0&viewDate=&currentPage=1&postListTopCurrentPage=1&from=postView)\n",
    "  \n",
    "  - [File, directory 관련 링크](https://www.geeksforgeeks.org/python-os-listdir-method/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 압축 하기, 풀기 ([참고](https://yganalyst.github.io/data_handling/memo_2/))\n",
    "\n",
    "```python\n",
    "    import zipfile\n",
    "\n",
    "    # 압축 풀기\n",
    "    file = zipfile.ZipFile('example.zip')\n",
    "    # 전체 압축 풀기\n",
    "    file.extractall() # 또는 저장될 경로 입력\n",
    "    # 특정 파일 압축 풀기\n",
    "    file.extract('선택할 파일', '저장할 경로')\n",
    "    \n",
    "    \n",
    "    # 압축하기\n",
    "    fzip = zipfile.ZipFile('example.zip', 'w')\n",
    "    fzip.write('example.txt')\n",
    "    fzip.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구글드라이브 통해서 파일 다운로드 하기 ([참고1](https://hmdev.vercel.app/%EA%B5%AC%EA%B8%80-%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C-%ED%8C%8C%EC%9D%BC-wget,-curl-%ED%95%98%EA%B8%B0))\n",
    "\n",
    "* 쥬피터 셀 이용하는 방법 (gdown)\n",
    "    * 구글 드라이브 파일(폴더 x)을 '링크가 있는 모든 사용자' 액서스로 공유 설정해서 링크 복사\n",
    "    * 예시로 https://drive.google.com/file/d/1xaRFi3AoM7BHJ9omI-9cioS34hoKV3eU/view?usp=sharing에서 file/d/뒤에 id(1xaRFi3AoM7BHJ9omI-9cioS34hoKV3eU)를 복사\n",
    "    * 아래 'https://drive.google.com/uc?id=' 뒷부분에 붙여넣기\n",
    "\n",
    "```python\n",
    "import gdown\n",
    "\n",
    "gurl = 'https://drive.google.com/uc?id=1xaRFi3AoM7BHJ9omI-9cioS34hoKV3eU'\n",
    "gdown.download(gurl, 'pacu.zip')\n",
    "```\n",
    "* 그러나 위 방법으로 안되는 경우들이 있음 (파일이 아닌 폴더를 공유하는 경우 -> 압축해서 해결 / 파일 크기가 너무 큰 경우 -> 쪼개서 압축 / 하루에 한 계정으로 공유를 여러번 시도하다보면 그냥 막힘...)\n",
    "\n",
    "* [wget/curl를 이용한 방법](https://deeplify.dev/server/bash/download-google-drive-file-in-terminal)\n",
    "    * curl은 큰 용량의 파일에서는 안됨\n",
    "    * wget의 경우에도 마찬가지로 폴더가 아닌 파일에만 쓸 수 있고 큰 용량에 대해서도 시도 가능\n",
    "    * 쥬피터 커널에 아래 명령어 입력 ({FILEID} 대신 위 fileid 대체 + {FILENAME}에 저장할 파일 이름 지정하면 됨)  \n",
    "    wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILEID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILEID}\" -O {FILENAME} && rm -rf ~/cookies.txt\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waveform processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Savitzky-Golay filter** : convolution filter를 씌움\n",
    "  - scipy.signal.savgol_filter\n",
    "  \n",
    "  \n",
    "- **Welch** : 주어진 input이 주기적으로 반복된다고 가정(여기서 퓨리에 변환의 기본 각진동수 w 획득) -> Hann filter(삼각함수 형태)를 씌워 양쪽 끝을 0으로 맞춤. 그래야 주기적으로 반복할 수 있음 -> FFT(fast fourier transform)을 적용 -> output이 복소수이고 절반은 앞의 절반이 대칭으로 반복. 즉, 우리는 크기에만 관심이 있기에 이중 절반만 관심있고 크기를 취함\n",
    "  - scipy.signal.welch\n",
    "  \n",
    "  \n",
    "- **Butterworth filter** : band pass filter\n",
    "  - scipy.signal.butter\n",
    "- lowpass filter\n",
    "  - scipy.lfilter\n",
    "  \n",
    "  \n",
    "- **lowess filter** : 아주 정교하지만 오래걸림. 파형의 움직임을 뽑아낼 수 있음 -> 이걸로 noise 제거해서 파형이 움직이는 변위를 없앨 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python graph plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plane graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- plt.figure(figsize=(10, 5)) 를 하면 새로운 figure를 형성\n",
    "\n",
    "- 그래프 여러개를 그리고 싶을때(예를 들어 2x2), subplots나 subplot를 이용 ([차이점](https://m.blog.naver.com/PostView.nhn?blogId=heygun&logNo=221520454294&proxyReferer=https:%2F%2Fwww.google.com%2F))\n",
    "\n",
    "> fig, axes = subplots(nrows=2, ncols=1)\n",
    "\n",
    " - fig는 figure로 subplots로 소환된 그래프 전체를 지칭\n",
    " - axes는 ax들의 리스트. nrows x ncols 만큼 형성\n",
    " \n",
    "> ax = subplot(2,1,1)\n",
    "\n",
    " - ax는 개별 figure만 지칭\n",
    " \n",
    "> fig = plt.figure(figsize=(20,10)) <br>\n",
    "ax1 = fig.add_subplot(2,1,1)<br>\n",
    "ax1.plot(~)<br>\n",
    "ax1.set_xlim, set_title 등등\n",
    "\n",
    " - subplot과 비슷한 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [눈금(ticks) 설정](https://kongdols-room.tistory.com/84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Histogram Plotting ([Link](https://realpython.com/python-histograms/))\n",
    "\n",
    "\n",
    "### bars\n",
    "- 좋은 참고문헌: [막대그래프](http://hleecaster.com/python-matplotlib-bar-graph/)\n",
    "\n",
    "\n",
    "### dictionary\n",
    "```python\n",
    "    from collections import Counter\n",
    "    Counter(a) # return dictionary\n",
    "``` \n",
    "<br>\n",
    "\n",
    "### Visualization\n",
    "\n",
    "\n",
    "#### **matplotlib.pyplot의 hist 함수 이용** ([**자세한 인자 사용**](https://kongdols-room.tistory.com/94))\n",
    "- bins: histogram 값의 기준값 설정 (ex. [0, 1, 2, 3]으로 하면 0, 1, 2, 3에 대한 빈도를 표현함) \n",
    "    \n",
    "#### pd.Series.plot.hist, pd.Series.value_counts 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T13:26:18.967000Z",
     "start_time": "2020-11-18T13:26:18.409146Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 80.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d = np.random.laplace(loc=15, scale=3, size=500)\n",
    "# An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "n, bins, patches = plt.hist(x=d, bins='auto', color='#0504aa', alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('My Very Own Histogram')\n",
    "plt.text(23, 45, r'$\\mu=15, b=3$')\n",
    "maxfreq = n.max()\n",
    "# Set a clean upper y-axis limit.\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T13:27:27.459263Z",
     "start_time": "2020-11-18T13:27:26.938908Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Generate data on commute times.\n",
    "size, scale = 1000, 10\n",
    "commutes = pd.Series(np.random.gamma(scale, size=size) ** 1.5)\n",
    "\n",
    "commutes.plot.hist(grid=True, bins=20, rwidth=0.9,\n",
    "                   color='#607c8e')\n",
    "plt.title('Commute Times for 1,000 Commuters')\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('Commute Time')\n",
    "plt.grid(axis='y', alpha=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seaborn library 이용\n",
    "* [seaborn tutorial](https://junstar92.tistory.com/90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python-pptx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [업무 자동화 - 파이썬으로 파워포인트 편집하기](https://ai-creator.tistory.com/208)\n",
    "  - slide_layouts의 index: 차례대로 0부터 시작\n",
    "    - Title (presentation title slide)\n",
    "    - Title and Content\n",
    "    - Section Header (sometimes called Segue)\n",
    "    - Two Content (side by side bullet textboxes)\n",
    "    - Comparison (same but additional title for each side by side content box)\n",
    "    - Title Only\n",
    "    - Blank\n",
    "    - Content with Caption\n",
    "    - Picture with Caption\n",
    "   \n",
    "  - matplotlib의 figure를 넘길때 fig.savefig(file_path)해서 slide.shapes.add_picture(file_path, left, top)해서 넘긴 후 os.remove(file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 편리한 python 문법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for 문에서 몇번째 index 돌리는지 알고 싶을때 사용\n",
    "```python\n",
    "    for i, element in enumerate(list_ex):\n",
    "        # enumerate는 (idx 번호, 컬렉션의 원소)를 반환\n",
    "```\n",
    "- 첫 번째 케이스만 다르게 돌리고 싶은 경우 사용하면 좋음\n",
    "```python\n",
    "    for i, element in enumerate(list_ex):\n",
    "        if i:\n",
    "            #첫 번째 원소에 대해 처리하고 싶은 내용\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermark 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jupyter notebook 매직 커맨드로 모듈 버전, OS 정보 등을 출력하는 watermark 모듈](https://pinkwink.kr/1235)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문헌 관리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Zotero ([guide](https://www.zotero.org/support/quick_start_guide)) : google docs에서도 쓸 수 있어 편하고 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 좋은 참고사이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [wikidocs](https://wikidocs.net/61375)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 의학연구에서 실수하기 쉬운 부분들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set, Test set split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한 환자에서 여러개의 데이터를 뽑아내는 경우, 이들 전체를 shuffle해서 training, test set 나누면 안됨. 환자의 caseid 단위로 나눠야 함\n",
    "  - 그냥 전체 데이터에 대해서 shuffle를 하면 한 환자에서 일부는 train, 일부는 test set에 들어가 더욱 쉽게 맞힘\n",
    "  \n",
    "  \n",
    "- validation set도 각 환자에 대해서 augmentation이 많이 되었으면 마찬가지 이유로 환자 caseid에 대해서 나눠줘야 함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsolved Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. y를 event 발생이라고 뒀을 때, non-event 사건은 얼마나 뽑아야 하는지\n",
    "<br> ex) 뇌파에서 특정 spike를 detect하는데 특정 spike와  \n",
    " a) 보통은 전체 incidence 발생율 대로 나누면 되지 않을까."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [RNN visualization](https://github.com/OverLordGoldDragon/see-rnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "457.327px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
