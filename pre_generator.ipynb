{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305fb59-3227-4f09-ae7b-d6f8879c0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from pyvital2 import arr\n",
    "\n",
    "\n",
    "def smooth(y):\n",
    "    #return savitzky_golay(y, window_size=2001, order=3)\n",
    "    return lowess(y)\n",
    "\n",
    "\n",
    "# 0.2가 제일 잘 없앴음\n",
    "def lowess(y, f=0.2):\n",
    "    x = np.arange(0, len(y))\n",
    "    return sm.nonparametric.lowess(y, x, frac=f, it=0)[:, 1].T\n",
    "\n",
    "\n",
    "# 피크 사이 wave를 모두 같은 length로 만들기 위한 함수\n",
    "def linear_connection(list, idx):\n",
    "    int_idx = int(idx)\n",
    "    return list[int_idx] + (list[int_idx+1] - list[int_idx]) * (idx - int_idx)\n",
    "\n",
    "\n",
    "def preprocess(file_path, LEN_INPUT = 20, OVERLAP = 10, SRATE = 100):\n",
    "    ### file_path : path for inputs extracted from vital file ###\n",
    "    ### LEN_INPUT : length of input, OVERLAP : overlap of each input, SRATE : sampling rate from vital data ###\n",
    "\n",
    "\n",
    "    # path for cache\n",
    "    if not os.path.exists('./cache'):\n",
    "        os.mkdir('./cache')\n",
    "    if not os.path.exists('./cache/peaks'):\n",
    "        os.mkdir('./cache/peaks')\n",
    "    if not os.path.exists(f\"cache/peaks/PPG_{SRATE}Hz_1min_seg\"):\n",
    "        os.mkdir(f\"cache/peaks/PPG_{SRATE}Hz_1min_seg\")\n",
    "    if not os.path.exists(f\"cache/peaks/ECG_{SRATE}Hz_1min_seg\"):\n",
    "        os.mkdir(f\"cache/peaks/ECG_{SRATE}Hz_1min_seg\")        \n",
    "    if not os.path.exists('./cache/preprocess'):\n",
    "        os.mkdir('./cache/preprocess')\n",
    "    \n",
    "    \n",
    "    # dataframe to save preprocessing info\n",
    "    n_aug = int((60-LEN_INPUT)/OVERLAP) + 1   # number of data augmentation\n",
    "    column_list = ['file_path'] + [str(i+1) for i in range(n_aug*2)]\n",
    "    df_preprocess = pd.DataFrame(columns = column_list)\n",
    "\n",
    "\n",
    "    # set variables\n",
    "    error_list = []\n",
    "    f_num = 0\n",
    "    initial = f_num\n",
    "    interval = 10\n",
    "\n",
    "\n",
    "    caseids = os.listdir(file_path)\n",
    "    for caseid in caseids[initial:initial+interval]:\n",
    "        caseid = caseid[:-4]\n",
    "        f_num += 1\n",
    "        print('###Input', f_num,'/ '+str(len(caseids))+': '+caseid+'###')\n",
    "\n",
    "\n",
    "        # vital data 불러오기    \n",
    "        vals = np.load(f'{file_path}/{caseid}.npz')\n",
    "\n",
    "\n",
    "        #dataframe에 새로운 행 만들기\n",
    "        df_preprocess.loc[f_num-1,'file_path'] = caseid\n",
    "\n",
    "        ppg_cache = f\"cache/peaks/PPG_{SRATE}Hz_1min_seg/\" + caseid\n",
    "        ecg_cache = f\"cache/peaks/ECG_{SRATE}Hz_1min_seg/\" + caseid    \n",
    "        ecg_cache2 = f\"cache/peaks/ECG_{SRATE}Hz_1min_seg/\" + caseid\n",
    "\n",
    "\n",
    "        # 20초 단위로 끊기\n",
    "        for i in range(n_aug):\n",
    "            print('  segment', i+1, end='')\n",
    "            start_idx = i*OVERLAP*SRATE # 500i\n",
    "            end_idx = (i*OVERLAP + LEN_INPUT)*SRATE # 500i + 1000\n",
    "\n",
    "\n",
    "            ### non-event input ###\n",
    "            seg_ppg = vals['nPPG'][start_idx:end_idx]\n",
    "            seg_ecg = vals['nECG'][start_idx:end_idx]\n",
    "\n",
    "\n",
    "            ## 1. 결측치 처리 ##             \n",
    "            # df.isnull().sum() 하면 더 간단하게 가능하나 애초에 NRS에 해당하는 vital data가 120초 보다 짧은 경우\n",
    "            nan_ppg_list = np.isnan(seg_ppg)\n",
    "            nan_ecg_list = np.isnan(seg_ecg)\n",
    "            nan_ppg_perc = np.sum(nan_ppg_list) / LEN_INPUT / SRATE\n",
    "            nan_ecg_perc = np.sum(nan_ecg_list) / LEN_INPUT / SRATE\n",
    "\n",
    "            # ECG, PPG 둘다 결측치인 부분\n",
    "            nan_both_perc = 0\n",
    "            for j in range(len(seg_ppg)):\n",
    "                if nan_ppg_list[j] and  nan_ecg_list[j]:\n",
    "                    nan_both_perc += 1\n",
    "            nan_both_perc /= (LEN_INPUT*SRATE)\n",
    "\n",
    "            # segment의 결측치 비율 정보\n",
    "            nan_info = [nan_ppg_perc, nan_ecg_perc, nan_both_perc]\n",
    "\n",
    "            # 결측치가 많은 경우, noise 확인할 것도 없이 False -  이 경우의 noise_info는 -1로 처리\n",
    "            if nan_ppg_perc > 0.05 or nan_ecg_perc > 0.05 or nan_both_perc > 0.05:\n",
    "                df_preprocess.loc[f_num-1,str(i+1)] = (False, nan_info, [-1, -1])\n",
    "                print('too much missing data')\n",
    "                continue\n",
    "\n",
    "\n",
    "            ## 2. Noise 처리 ##\n",
    "            # peak detection\n",
    "            if os.path.exists(ppg_cache+'_n{}'.format(i+1)):\n",
    "                _, ppg_peak = pickle.load(open(ppg_cache+'_n{}'.format(i+1), 'rb'))\n",
    "                ecg_peak = pickle.load(open(ecg_cache+'_n{}'.format(i+1), 'rb'))\n",
    "                print('...loaded peak...', end='')\n",
    "\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    min_peak, ppg_peak = arr.detect_peaks(pd.DataFrame(seg_ppg).fillna(method='ffill', axis=0).fillna(method='bfill', axis=0).values.flatten(), SRATE)\n",
    "                    ecg_peak = arr.detect_qrs(pd.DataFrame(seg_ecg).fillna(method='ffill', axis=0).fillna(method='bfill', axis=0).values.flatten(), SRATE)\n",
    "\n",
    "\n",
    "                except Exception as e:\n",
    "                    print('error of', e)\n",
    "                    error_list.append(caseid)\n",
    "                    df_preprocess.loc[f_num-1,str(i+1)] = (False, nan_info, [-3, -3])\n",
    "                    continue\n",
    "\n",
    "\n",
    "                if len(ppg_peak)==0:\n",
    "                    print('no peak')\n",
    "\n",
    "\n",
    "                pickle.dump((min_peak, ppg_peak), open(ppg_cache+'_n{}'.format(i+1), 'wb'))\n",
    "                pickle.dump(ecg_peak, open(ecg_cache+'_n{}'.format(i+1), 'wb'))\n",
    "                print('...saved peak...', end='')\n",
    "\n",
    "\n",
    "            # 10초 segment 내의 ppg, ecg peak idx\n",
    "            #seg_ppg_min = ppg_min[(start_idx<=np.array(ppg_min)) & (np.array(ppg_min)<end_idx)]\n",
    "            idx_ppg_peak = ppg_peak\n",
    "            idx_ecg_peak = ecg_peak\n",
    "\n",
    "\n",
    "            # peak가 HR 30~150 -> 20s - min 10 peaks(HR30)\n",
    "            # peak 개수가 기준 미달이면 noise 계산 자세히 할 필요없이 False - 이 경우의 noise_info는 -2로 처리\n",
    "            if len(idx_ppg_peak)<5/10*LEN_INPUT or len(idx_ecg_peak)<5/10*LEN_INPUT:\n",
    "                df_preprocess.loc[f_num-1,str(i+1)] = (False, nan_info, [-2, -2])\n",
    "                print('too less peaks')\n",
    "                continue\n",
    "\n",
    "\n",
    "            # 20초 segment 내의 ppg, ecg peak value\n",
    "            #print(len(seg_ppg), idx_ppg_peak)\n",
    "            val_ppg_peak = [seg_ppg[k] for k in idx_ppg_peak]\n",
    "            val_ecg_peak = [seg_ecg[k] for k in idx_ecg_peak]\n",
    "\n",
    "            # peak와 peak 사이 interval에 대한 noise 여부 -> 따라서 길이는 peak - 1\n",
    "            bool_noise_ppg = [False for k in range(len(idx_ppg_peak)-1)]\n",
    "            bool_noise_ecg = [False for k in range(len(idx_ecg_peak)-1)]\n",
    "\n",
    "\n",
    "            #  2.1 peak 간격 이상한 noise (HR 30~150 -> HBI 0.4s ~ 2s로 SRATE 곱해주면 40~200)\n",
    "            for k in range(len(bool_noise_ppg)):\n",
    "                if not 0.4*SRATE < idx_ppg_peak[k+1] - idx_ppg_peak[k] < 2*SRATE:\n",
    "                    bool_noise_ppg[k] = True\n",
    "            for k in range(len(bool_noise_ecg)):\n",
    "                if not 0.4*SRATE < idx_ecg_peak[k+1] - idx_ecg_peak[k] < 2*SRATE:\n",
    "                    bool_noise_ecg[k] = True\n",
    "\n",
    "\n",
    "            # 2.2 모양 이상한 noise\n",
    "            # wave interval into same length(2s(200))\n",
    "            len_wave = 2*SRATE\n",
    "            norm_seg_ppg, norm_seg_ecg = [], []\n",
    "\n",
    "            for k in range(len(bool_noise_ppg)):\n",
    "                len_interval_ppg = idx_ppg_peak[k+1] - idx_ppg_peak[k]\n",
    "\n",
    "                # peak 사이 wave를 모두 같은 길이로 변환\n",
    "                norm_seg_ppg.append([linear_connection(seg_ppg[idx_ppg_peak[k]:idx_ppg_peak[k+1]+1], n/len_wave*len_interval_ppg) for n in range(len_wave)])\n",
    "\n",
    "            for k in range(len(bool_noise_ecg)):\n",
    "                len_interval_ecg = idx_ecg_peak[k+1] - idx_ecg_peak[k]\n",
    "\n",
    "                # peak 사이 wave를 모두 같은 길이로 변환\n",
    "                norm_seg_ecg.append([linear_connection(seg_ecg[idx_ecg_peak[k]:idx_ecg_peak[k+1]+1], n/len_wave*len_interval_ecg) for n in range(len_wave)])\n",
    "\n",
    "\n",
    "            # wave interval 사이 correlation 계산 - PPG\n",
    "            mean_wave_ppg = np.nanmean(norm_seg_ppg, axis = 0)\n",
    "            mean_wave_ppg = pd.DataFrame(mean_wave_ppg).fillna(method='ffill', axis=0).fillna(method='bfill', axis=0).values.flatten()\n",
    "            norm_seg_ppg = pd.DataFrame(norm_seg_ppg).fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).values\n",
    "            for k in range(len(bool_noise_ppg)):\n",
    "                if np.corrcoef(norm_seg_ppg[k], mean_wave_ppg)[0,1] < 0.9:\n",
    "                    bool_noise_ppg[k] = True\n",
    "            noise_ppg_perc = np.sum(bool_noise_ppg) / len(bool_noise_ppg)\n",
    "\n",
    "            # wave interval 사이 correlation 계산 - ECG                \n",
    "            mean_wave_ecg = np.nanmean(norm_seg_ecg, axis = 0)\n",
    "            mean_wave_ecg = pd.DataFrame(mean_wave_ecg).fillna(method='ffill', axis=0).fillna(method='bfill', axis=0).values.flatten()\n",
    "            norm_seg_ecg = pd.DataFrame(norm_seg_ecg).fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).values\n",
    "            for k in range(len(bool_noise_ecg)):\n",
    "                if np.corrcoef(norm_seg_ecg[k], mean_wave_ecg)[0,1] < 0.9:\n",
    "                    bool_noise_ecg[k] = True\n",
    "            noise_ecg_perc = np.sum(bool_noise_ecg) / len(bool_noise_ecg)\n",
    "\n",
    "            # segment의 noise 비율 정보\n",
    "            noise_info = [noise_ppg_perc, noise_ecg_perc]\n",
    "\n",
    "            # segment를 input으로 써도 되는지\n",
    "            if nan_ppg_perc < 0.05 and nan_ecg_perc < 0.05 and nan_both_perc < 0.05 and noise_ppg_perc < 0.1 and noise_ecg_perc < 0.1:\n",
    "                bool_pass = True\n",
    "            else:\n",
    "                bool_pass = False\n",
    "\n",
    "            # 이 segment의 정보를 dataframe에 저장 - (전처리 성공여부, 전처리 nan 비율, 전처리 noise 비율, 통증 점수)\n",
    "            df_preprocess.loc[f_num-1,f'{i+1}'] = [bool_pass, nan_info, noise_info, 0, 0] #{'pass':bool_pass, 'nan_perc':nan_info, 'noise_perc':noise_info, 'tss':0, 'cisa':0}        \n",
    "            print('preprocessing done...', end='')\n",
    "            ##########################################################################\n",
    "\n",
    "\n",
    "            ### event input ###\n",
    "            seg_ppg = vals['PPG'][start_idx:end_idx]\n",
    "            seg_ecg = vals['ECG'][start_idx:end_idx]\n",
    "\n",
    "\n",
    "            ## 1. 결측치 처리 ##              \n",
    "            # df.isnull().sum() 하면 더 간단하게 가능하나 애초에 NRS에 해당하는 vital data가 120초 보다 짧은 경우\n",
    "            nan_ppg_list = np.isnan(seg_ppg)\n",
    "            nan_ecg_list = np.isnan(seg_ecg)\n",
    "            nan_ppg_perc = np.sum(nan_ppg_list) / LEN_INPUT / SRATE\n",
    "            nan_ecg_perc = np.sum(nan_ecg_list) / LEN_INPUT / SRATE\n",
    "\n",
    "            # ECG, PPG 둘다 결측치인 부분\n",
    "            nan_both_perc = 0\n",
    "            for j in range(len(seg_ppg)):\n",
    "                if nan_ppg_list[j] and  nan_ecg_list[j]:\n",
    "                    nan_both_perc += 1\n",
    "            nan_both_perc /= (LEN_INPUT*SRATE)\n",
    "\n",
    "            # segment의 결측치 비율 정보\n",
    "            nan_info = [nan_ppg_perc, nan_ecg_perc, nan_both_perc]\n",
    "\n",
    "            # 결측치가 많은 경우, noise 확인할 것도 없이 False -  이 경우의 noise_info는 -1로 처리\n",
    "            if nan_ppg_perc > 0.05 or nan_ecg_perc > 0.05 or nan_both_perc > 0.05:\n",
    "                df_preprocess.loc[f_num-1,str(i+1)] = (False, nan_info, [-1, -1])\n",
    "                print('too much missing data')\n",
    "                continue\n",
    "\n",
    "\n",
    "            ## 2. Noise 처리 ##\n",
    "            # peak detection\n",
    "            if os.path.exists(ppg_cache+'_{}'.format(i+1)):\n",
    "                _, ppg_peak = pickle.load(open(ppg_cache+'_n{}'.format(i+1), 'rb'))\n",
    "                ecg_peak = pickle.load(open(ecg_cache+'_n{}'.format(i+1), 'rb'))\n",
    "                print('...loaded peak...', end='')\n",
    "\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    min_peak, ppg_peak = arr.detect_peaks(pd.DataFrame(seg_ppg).fillna(method='ffill', axis=0).fillna(method='bfill', axis=0).values.flatten(), SRATE)\n",
    "                    ecg_peak = arr.detect_qrs(pd.DataFrame(seg_ecg).fillna(method='ffill', axis=0).fillna(method='bfill', axis=0).values.flatten(), SRATE)\n",
    "\n",
    "\n",
    "                except Exception as e:\n",
    "                    print('error of', e)\n",
    "                    error_list.append(caseid)\n",
    "                    df_preprocess.loc[f_num-1,str(i+1)] = (False, nan_info, [-3, -3])\n",
    "                    continue\n",
    "\n",
    "\n",
    "                if len(ppg_peak)==0:\n",
    "                    print('no peak')\n",
    "\n",
    "\n",
    "                pickle.dump((min_peak, ppg_peak), open(ppg_cache+'_n{}'.format(i+1), 'wb'))\n",
    "                pickle.dump(ecg_peak, open(ecg_cache+'_n{}'.format(i+1), 'wb'))\n",
    "                print('...saved peak...', end='')\n",
    "\n",
    "\n",
    "            # 10초 segment 내의 ppg, ecg peak idx\n",
    "            #seg_ppg_min = ppg_min[(start_idx<=np.array(ppg_min)) & (np.array(ppg_min)<end_idx)]\n",
    "            idx_ppg_peak = ppg_peak\n",
    "            idx_ecg_peak = ecg_peak\n",
    "\n",
    "\n",
    "            # peak가 HR 30~150 -> 20s - min 10 peaks(HR30)\n",
    "            # peak 개수가 기준 미달이면 noise 계산 자세히 할 필요없이 False - 이 경우의 noise_info는 -2로 처리\n",
    "            if len(idx_ppg_peak)<5/10*LEN_INPUT or len(idx_ecg_peak)<5/10*LEN_INPUT:\n",
    "                df_preprocess.loc[f_num-1,str(i+1)] = (False, nan_info, [-2, -2])\n",
    "                print('too less peaks')\n",
    "                continue\n",
    "\n",
    "\n",
    "            # 20초 segment 내의 ppg, ecg peak value\n",
    "            #print(len(seg_ppg), idx_ppg_peak)\n",
    "            val_ppg_peak = [seg_ppg[k] for k in idx_ppg_peak]\n",
    "            val_ecg_peak = [seg_ecg[k] for k in idx_ecg_peak]\n",
    "\n",
    "            # peak와 peak 사이 interval에 대한 noise 여부 -> 따라서 길이는 peak - 1\n",
    "            bool_noise_ppg = [False for k in range(len(idx_ppg_peak)-1)]\n",
    "            bool_noise_ecg = [False for k in range(len(idx_ecg_peak)-1)]\n",
    "\n",
    "\n",
    "            #  2.1 peak 간격 이상한 noise (HR 30~150 -> HBI 0.4s ~ 2s로 SRATE 곱해주면 40~200)\n",
    "            for k in range(len(bool_noise_ppg)):\n",
    "                if not 0.4*SRATE < idx_ppg_peak[k+1] - idx_ppg_peak[k] < 2*SRATE:\n",
    "                    bool_noise_ppg[k] = True\n",
    "            for k in range(len(bool_noise_ecg)):\n",
    "                if not 0.4*SRATE < idx_ecg_peak[k+1] - idx_ecg_peak[k] < 2*SRATE:\n",
    "                    bool_noise_ecg[k] = True\n",
    "\n",
    "\n",
    "            # 2.2 모양 이상한 noise\n",
    "            # wave interval into same length(2s(200))\n",
    "            len_wave = 2*SRATE\n",
    "            norm_seg_ppg, norm_seg_ecg = [], []\n",
    "\n",
    "            for k in range(len(bool_noise_ppg)):\n",
    "                len_interval_ppg = idx_ppg_peak[k+1] - idx_ppg_peak[k]\n",
    "\n",
    "                # peak 사이 wave를 모두 같은 길이로 변환\n",
    "                norm_seg_ppg.append([linear_connection(seg_ppg[idx_ppg_peak[k]:idx_ppg_peak[k+1]+1], n/len_wave*len_interval_ppg) for n in range(len_wave)])\n",
    "\n",
    "            for k in range(len(bool_noise_ecg)):\n",
    "                len_interval_ecg = idx_ecg_peak[k+1] - idx_ecg_peak[k]\n",
    "\n",
    "                # peak 사이 wave를 모두 같은 길이로 변환\n",
    "                norm_seg_ecg.append([linear_connection(seg_ecg[idx_ecg_peak[k]:idx_ecg_peak[k+1]+1], n/len_wave*len_interval_ecg) for n in range(len_wave)])\n",
    "\n",
    "\n",
    "            # wave interval 사이 correlation 계산 - PPG\n",
    "            mean_wave_ppg = np.nanmean(norm_seg_ppg, axis = 0)\n",
    "            mean_wave_ppg = pd.DataFrame(mean_wave_ppg).fillna(method='ffill', axis=0).fillna(method='bfill', axis=0).values.flatten()\n",
    "            norm_seg_ppg = pd.DataFrame(norm_seg_ppg).fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).values\n",
    "            for k in range(len(bool_noise_ppg)):\n",
    "                if np.corrcoef(norm_seg_ppg[k], mean_wave_ppg)[0,1] < 0.9:\n",
    "                    bool_noise_ppg[k] = True\n",
    "            noise_ppg_perc = np.sum(bool_noise_ppg) / len(bool_noise_ppg)\n",
    "\n",
    "\n",
    "            # wave interval 사이 correlation 계산 - ECG                \n",
    "            mean_wave_ecg = np.nanmean(norm_seg_ecg, axis = 0)\n",
    "            mean_wave_ecg = pd.DataFrame(mean_wave_ecg).fillna(method='ffill', axis=0).fillna(method='bfill', axis=0).values.flatten()\n",
    "            norm_seg_ecg = pd.DataFrame(norm_seg_ecg).fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).values\n",
    "            for k in range(len(bool_noise_ecg)):\n",
    "                if np.corrcoef(norm_seg_ecg[k], mean_wave_ecg)[0,1] < 0.9:\n",
    "                    bool_noise_ecg[k] = True\n",
    "            noise_ecg_perc = np.sum(bool_noise_ecg) / len(bool_noise_ecg)\n",
    "\n",
    "\n",
    "            # segment의 noise 비율 정보\n",
    "            noise_info = [noise_ppg_perc, noise_ecg_perc]\n",
    "\n",
    "            # segment를 input으로 써도 되는지\n",
    "            if nan_ppg_perc < 0.05 and nan_ecg_perc < 0.05 and nan_both_perc < 0.05 and noise_ppg_perc < 0.1 and noise_ecg_perc < 0.1:\n",
    "                bool_pass = True\n",
    "            else:\n",
    "                bool_pass = False\n",
    "\n",
    "\n",
    "            # 통증 점수 계산\n",
    "            ### TSS(total surgical stimulation) = 1.57 - rftn20_ce / 3\n",
    "            ### CISA(combined index of stimulus and analgesia) = stim_intensity - beta * ce + gamma, beta = 1/8, gamma = 1.5, stim_intensity = 5.5 \n",
    "            rftn = vals['RFTN'][start_idx:end_idx]\n",
    "            rftn = np.mean(rftn[~np.isnan(rftn)])\n",
    "            tss = 1.57 - rftn / 3\n",
    "            if tss < 0:\n",
    "                tss = 0\n",
    "            cisa = 7 - rftn / 8\n",
    "\n",
    "\n",
    "            # 이 segment의 정보를 dataframe에 저장\n",
    "            df_preprocess.loc[f_num-1,f'{i+n_aug+1}'] = [bool_pass, nan_info, noise_info, tss, cisa] #{'pass':bool_pass, 'nan_perc':nan_info, 'noise_perc':noise_info, 'tss':tss, 'cisa':cisa}       \n",
    "            print('preprocessing done...', end='')\n",
    "            ###\n",
    "\n",
    "\n",
    "    print(f'dumping cache of d_preprocess {f_num}/{len(caseids)}')\n",
    "    pickle.dump(df_preprocess, open(f'cache/preprocess/df_preprocess_{initial}-{initial+interval}', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963f627-ef99-4e3b-aad7-ca978b190f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # 전처리 성공한 case에 대해 lowess filter 적용\n",
    "            if bool_pass:\n",
    "                print('passed...lowess filtering...', end='')\n",
    "                save_path = '../../cranberry2/Preprocessing/cache/lowess_filtered/preprocess6/pacu_'+caseid\n",
    "                if os.path.exists(save_path+'_{}'.format(i+1)):\n",
    "                    print('already exists')\n",
    "                    continue\n",
    "\n",
    "\n",
    "                start_idx = i*OVERLAP*250\n",
    "                end_idx = (i*OVERLAP + LEN_INPUT)*250\n",
    "\n",
    "\n",
    "                # ECG 250Hz vital + 피크 뽑기\n",
    "                seg_ecg2 = df_ecg.loc[start_idx:end_idx-1]\n",
    "                ecg_inp = seg_ecg2[['ECG']].fillna(method='ffill', axis=0).fillna(method='bfill', axis=0).values.flatten()\n",
    "\n",
    "                try:\n",
    "                    ecg_peak2 = arr.detect_qrs(ecg_inp, 250)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print('error on 250Hz peak:', e)\n",
    "\n",
    "                else:\n",
    "                    pickle.dump(ecg_peak2, open(ecg_cache2+'_{}'.format(i+1),'wb'))\n",
    "\n",
    "\n",
    "                # PPG 100 Hz vital\n",
    "                ppg_inp = pd.DataFrame(seg_ppg).fillna(method='ffill', axis=0).fillna(method='bfill', axis=0).values.flatten()\n",
    "                #ppg_inp = signal.resample(ppg_inp, 250*LEN_INPUT)\n",
    "\n",
    "\n",
    "                # lowess filter 적용\n",
    "                ppg_input = ppg_inp - smooth(ppg_inp)\n",
    "                ecg_input = ecg_inp - smooth(ecg_inp)\n",
    "\n",
    "\n",
    "                pickle.dump([ppg_input, ecg_input],  open(save_path+'_{}'.format(i+1), 'wb'))\n",
    "                print('done')\n",
    "\n",
    "\n",
    "            else:\n",
    "                print('failed')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "painstudy_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
